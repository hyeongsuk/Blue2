2025-08-29 04:26:11,056 - INFO - Starting Real EEG Optimization
2025-08-29 04:26:11,056 - INFO - Loading existing features from: /Users/hyeongsuk/Library/CloudStorage/OneDrive-ê°œì¸/HS_ë…¼ë¬¸ì‘ì„±/KOOS/results/outputs/real_eeg_features.csv
2025-08-29 04:26:11,912 - INFO - Loaded features: (10620, 782)
ğŸš€ REAL EEG DATA OPTIMIZATION
========================================
ğŸ“ Log file: logs/eeg_optimization_errors_20250829_042611.log
ğŸš€ Starting new session: 20250829_042611

ğŸ“Š PIPELINE STATUS
==================================================
Session ID: 20250829_042611
Last Updated: 2025-08-29T04:26:11.056480

Completed Steps: 0/4
  â³ feature_extraction: pending
  â³ ml_optimization: pending
  â³ validation_analysis: pending
  â³ paper_results: pending

Next Step: feature_extraction

ğŸ”„ STEP 1: FEATURE EXTRACTION
------------------------------
ğŸ“ Loading existing features from: /Users/hyeongsuk/Library/CloudStorage/OneDrive-ê°œì¸/HS_ë…¼ë¬¸ì‘ì„±/KOOS/results/outputs/real_eeg_features.csv
âœ… Loaded features: (10620, 782)
ğŸ” Selecting top features using Enhanced Method
ğŸ”¬ Enhanced Feature Selection Process
2025-08-29 04:26:43,545 - INFO - Starting LOSO-TTD analysis
ğŸ“Š Features: 150, Mean AUC: 0.589 (Â±0.009)
ğŸ“Š Features: 200, Mean AUC: 0.584 (Â±0.004)
ğŸ“Š Features: 250, Mean AUC: 0.579 (Â±0.010)
ğŸ“Š Features: 300, Mean AUC: 0.581 (Â±0.009)
ğŸ“Š Features: 350, Mean AUC: 0.565 (Â±0.028)
ğŸ“Š Features: 400, Mean AUC: 0.571 (Â±0.017)
ğŸ“Š Features: 450, Mean AUC: 0.570 (Â±0.007)
âœ… Optimal features selected: 150
ğŸ¯ Best CV AUC achieved: 0.589
âœ… Checkpoint saved: feature_extraction at 2025-08-29T04:26:43.539790

ğŸ•°ï¸ STEP 1.5: LOSO TIME-TO-DETECTION ANALYSIS
--------------------------------------------------
ğŸ•°ï¸ LOSO TIME-TO-DETECTION ANALYSIS (Reading from CSV)
==================================================
ğŸ“ Loading features from: /Users/hyeongsuk/Library/CloudStorage/OneDrive-ê°œì¸/HS_ë…¼ë¬¸ì‘ì„±/KOOS/results/outputs/real_eeg_features.csv
ğŸ“Š Dataset Summary:
   Total windows: 10620
   Unique subjects: 30
   Time range: 4.0 - 120.0 seconds
   Class distribution: Normal=5310, BLF=5310
Computing AUC(T):   0%|          | 0/4 [00:00<?, ?it/s]Computing AUC(T):  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:01,  1.67it/s]Computing AUC(T):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.61it/s]Computing AUC(T):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:02<00:00,  1.42it/s]Computing AUC(T): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.41it/s]Computing AUC(T): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.45it/s]

ğŸ“Š Computing Bootstrap Confidence Intervals...
Bootstrap CI:   0%|          | 0/4 [00:00<?, ?it/s]Bootstrap CI:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:26<01:20, 26.73s/it]Bootstrap CI:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [01:03<01:05, 32.73s/it]Bootstrap CI:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [01:26<00:28, 28.14s/it]Bootstrap CI: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [01:48<00:00, 25.69s/it]Bootstrap CI: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [01:48<00:00, 27.07s/it]

ğŸ­ Negative Control Analysis...
ğŸ­ Running negative control with shuffled labels...
Negative Control:   0%|          | 0/4 [00:00<?, ?it/s]Negative Control:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  1.08s/it]Negative Control:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.13s/it]Negative Control:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.45s/it]Negative Control: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.59s/it]                                                               2025-08-29 04:28:42,255 - INFO - Starting ML optimization

âš–ï¸ Equivalence Testing...
âš–ï¸ Testing equivalence with margin Â±0.03...
ğŸ’¾ Saving LOSO-TTD results...
âœ… AUC vs Time saved: /Users/hyeongsuk/Library/CloudStorage/OneDrive-ê°œì¸/HS_ë…¼ë¬¸ì‘ì„±/KOOS/results/outputs/auc_vs_time.csv
âœ… MDT Summary saved: /Users/hyeongsuk/Library/CloudStorage/OneDrive-ê°œì¸/HS_ë…¼ë¬¸ì‘ì„±/KOOS/results/outputs/mdt_summary.csv
âœ… Negative Control saved: /Users/hyeongsuk/Library/CloudStorage/OneDrive-ê°œì¸/HS_ë…¼ë¬¸ì‘ì„±/KOOS/results/outputs/negative_control_auc.csv
âœ… Equivalence saved: /Users/hyeongsuk/Library/CloudStorage/OneDrive-ê°œì¸/HS_ë…¼ë¬¸ì‘ì„±/KOOS/results/outputs/equivalence.csv
âœ… AUC vs Time figure saved: /Users/hyeongsuk/Library/CloudStorage/OneDrive-ê°œì¸/HS_ë…¼ë¬¸ì‘ì„±/KOOS/results/outputs/fig_auc_vs_time.png
âœ… Negative Control figure saved: /Users/hyeongsuk/Library/CloudStorage/OneDrive-ê°œì¸/HS_ë…¼ë¬¸ì‘ì„±/KOOS/results/outputs/fig_negative_control.png
âœ… Equivalence figure saved: /Users/hyeongsuk/Library/CloudStorage/OneDrive-ê°œì¸/HS_ë…¼ë¬¸ì‘ì„±/KOOS/results/outputs/fig_equivalence.png

============================================================
ğŸ“Š LOSO TIME-TO-DETECTION ANALYSIS SUMMARY
============================================================
âŒ MDT@0.7: Not reached
âŒ MDT@0.75: Not reached

ğŸ­ Negative Control Mean AUC: 0.486 (expected â‰ˆ0.5)
============================================================
âœ… Checkpoint saved: loso_ttd_analysis at 2025-08-29T04:28:42.252620

ğŸ¯ STEP 2: ML OPTIMIZATION
------------------------------

ğŸš€ ENSEMBLE OPTIMIZATION (INTEGRATED)
=============================================
ğŸ“Š Input data shape: (10620, 782)
ğŸ“Š Input data type: <class 'numpy.ndarray'>
âœ… Final X shape: (10620, 782)

ğŸ—³ï¸ ADVANCED VOTING CLASSIFIER
========================================
ğŸ“Š Standard Voting AUC: 0.705
ğŸ” Computing optimal weights for ensemble...
Training base models:   0%|          | 0/4 [00:00<?, ?it/s]Training base models:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:13<00:40, 13.43s/it]Training base models:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:23<00:22, 11.24s/it]Training base models:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [10:48<04:51, 291.82s/it]   lr: CV AUC = 0.652 (Â±0.008)
   rf: CV AUC = 0.712 (Â±0.008)
   svm: CV AUC = 0.782 (Â±0.006)
Training base models: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [10:49<00:00, 176.87s/it]Training base models: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [10:49<00:00, 162.38s/it]
   nb: CV AUC = 0.570 (Â±0.013)

ğŸ“Š Optimal weights calculated:
   lr: 0.203
   rf: 0.273
   svm: 0.389
   nb: 0.135
ğŸ¯ Weighted Voting AUC: 0.760
ğŸ“ˆ Improvement: +5.4%

ğŸ—ï¸ STACKING ENSEMBLE
==============================
Training stacking models:   0%|          | 0/3 [00:00<?, ?it/s]Training stacking models:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [14:54<29:49, 894.88s/it]Training stacking models:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [23:54<11:25, 685.70s/it]Training stacking models: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [33:12<00:00, 627.49s/it]Training stacking models: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [33:12<00:00, 664.12s/it]
2025-08-29 05:16:41,872 - INFO - ML optimization completed successfully
2025-08-29 05:16:42,042 - INFO - ML optimization completed successfully
2025-08-29 05:16:42,042 - INFO - Starting validation analysis
ğŸ¯ Stacking + LogisticRegression: AUC = 0.849
ğŸ¯ Stacking + RandomForest: AUC = 0.819
ğŸ¯ Stacking + SVM: AUC = 0.829

ğŸ† Best Stacking Model: LogisticRegression
ğŸ“Š Best Stacking AUC: 0.849

ğŸ“Š DETAILED CLASSIFICATION PERFORMANCE
   Baseline: AUC = 0.647
   Weighted_voting: AUC = 0.760
   Best_stacking: AUC = 0.849

ğŸ“‹ Classification Report:
              precision    recall  f1-score   support

           0       0.77      0.75      0.76      1062
           1       0.76      0.78      0.77      1062

    accuracy                           0.77      2124
   macro avg       0.77      0.77      0.77      2124
weighted avg       0.77      0.77      0.77      2124


ğŸ† ENSEMBLE RESULTS:
   Best method: best_stacking
   Best AUC: 0.849
   Improvement: +20.3%
âœ… Checkpoint saved: ml_optimization at 2025-08-29T05:16:41.873061

ğŸ” STEP 3: VALIDATION ANALYSIS
------------------------------
ğŸš€ COMPREHENSIVE VALIDATION ANALYSIS
=============================================
ğŸ“Š OVERFITTING ANALYSIS
==============================
Analyzing overfitting:   0%|          | 0/3 [00:00<?, ?it/s]Analyzing overfitting:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:15<00:30, 15.32s/it]Analyzing overfitting:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [08:33<04:59, 299.19s/it]Analyzing overfitting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [47:01<00:00, 1216.77s/it]Analyzing overfitting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [47:01<00:00, 940.64s/it] 
Logistic Regression:
  Final Training AUC: 0.746
  Final Validation AUC: 0.486
  Overfitting Gap: 0.260 (High)
Random Forest:
  Final Training AUC: 1.000
  Final Validation AUC: 0.557
  Overfitting Gap: 0.443 (High)
Random Forest (Complex):
  Final Training AUC: 1.000
  Final Validation AUC: 0.553
  Overfitting Gap: 0.447 (High)

ğŸ”„ CROSS-VALIDATION ANALYSIS
===================================
Cross-validation analysis:   0%|          | 0/3 [00:00<?, ?it/s]
CV folds for Baseline (LR):   0%|          | 0/3 [00:00<?, ?it/s][A
CV folds for Baseline (LR):  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:01<00:02,  1.03s/it][A
CV folds for Baseline (LR):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:03<00:01,  1.74s/it][A
CV folds for Baseline (LR): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  3.26s/it][A
                                                                         [ACross-validation analysis:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:08<00:16,  8.33s/it]Baseline (LR):
  3-fold CV: 0.639 (Â±0.003)
  5-fold CV: 0.647 (Â±0.006)
  10-fold CV: 0.649 (Â±0.010)

CV folds for Random Forest:   0%|          | 0/3 [00:00<?, ?it/s][A
CV folds for Random Forest:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:45<01:30, 45.07s/it][A
CV folds for Random Forest:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [02:44<01:28, 88.96s/it][A
CV folds for Random Forest: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [06:06<00:00, 140.65s/it][A
                                                                          [ACross-validation analysis:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [06:15<03:39, 219.26s/it]Random Forest:
  3-fold CV: 0.855 (Â±0.005)
  5-fold CV: 0.871 (Â±0.006)
  10-fold CV: 0.878 (Â±0.008)

CV folds for Optimized LR:   0%|          | 0/3 [00:00<?, ?it/s][A
CV folds for Optimized LR:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:08<00:16,  8.47s/it][A
CV folds for Optimized LR:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:27<00:14, 14.54s/it][A
CV folds for Optimized LR: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [01:20<00:00, 32.09s/it][A
                                                                        [ACross-validation analysis: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [07:35<00:00, 155.78s/it]Cross-validation analysis: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [07:35<00:00, 151.82s/it]
Optimized LR:
  3-fold CV: 0.638 (Â±0.002)
  5-fold CV: 0.649 (Â±0.007)
  10-fold CV: 0.651 (Â±0.011)

ğŸ“ˆ STATISTICAL SIGNIFICANCE TEST
========================================
Baseline AUC: 0.649 (Â±0.010)
Optimized AUC: 0.651 (Â±0.011)
Improvement: +0.1%
t-statistic: 0.658
p-value: 0.5272
Cohen's d: 0.126
Significance: ns (Not significant)
Effect size: Small

ğŸ† BENCHMARK COMPARISON
============================
Literature Comparison (AUC):
--------------------------------------------------
Ranking benchmarks:   0%|          | 0/6 [00:00<?, ?it/s]                                                         2025-08-29 06:12:18,507 - INFO - Validation analysis completed
2025-08-29 06:12:18,508 - INFO - Starting paper results generation
 1. ğŸ“Š Eye State Detection      : 0.950 (MBER + Feature Selection)
 2. ğŸ“Š Multi Attention (Opt)    : 0.941 (SVM + Optimized Features)
 3. ğŸ“Š Driver Fatigue (CNN)     : 0.837 (Deep Learning)
 4. ğŸ“Š Visual Attention (SVM)   : 0.744 (SVM + Band Power)
 5. ğŸ”¥ Our Method (Optimized)   : 0.704 (Ensemble + Optimization)
 6. ğŸ”¥ Our Method (Baseline)    : 0.647 (Logistic Regression + Band Power)

Our Performance Ranking:
  Baseline: 6/6 (100.0 percentile)
  Optimized: 5/6 (83.3 percentile)

ğŸ“‹ GENERATING VALIDATION REPORT
===================================
âœ… Validation report saved: /Users/hyeongsuk/Library/CloudStorage/OneDrive-ê°œì¸/HS_ë…¼ë¬¸ì‘ì„±/KOOS/results/validation/validation_report.md

âœ… VALIDATION ANALYSIS COMPLETED!
ğŸ“ Results saved in: /Users/hyeongsuk/Library/CloudStorage/OneDrive-ê°œì¸/HS_ë…¼ë¬¸ì‘ì„±/KOOS/results/validation
âœ… Checkpoint saved: validation_analysis at 2025-08-29T06:12:18.507295

ğŸ“Š STEP 4: PAPER RESULTS GENERATION
------------------------------
ğŸš€ GENERATING COMPREHENSIVE PAPER RESULTS
==================================================

1ï¸âƒ£ Running optimization analysis...
ğŸš€ COMPLETE ML OPTIMIZATION EXECUTION
=============================================
ğŸ“‚ Generating EEG feature data...
ğŸ§  Processing EEG data...
âœ… Found 30 EEG files
ğŸ§ª Using simulated EEG-like data for optimization test...
ğŸ“Š Generated data: 3540 samples, 180 features
ğŸ“Š Features: (3540, 180), Labels: (3540,)
ğŸ“Š Classes: (array([0, 1]), array([1773, 1767]))

==================================================
ğŸ¯ DAY 1: ENSEMBLE OPTIMIZATION
==================================================

ğŸš€ ENSEMBLE OPTIMIZATION (INTEGRATED)
=============================================
ğŸ“Š Input data shape: (3540, 180)
ğŸ“Š Input data type: <class 'numpy.ndarray'>
âœ… Final X shape: (3540, 180)

ğŸ—³ï¸ ADVANCED VOTING CLASSIFIER
========================================
ğŸ“Š Standard Voting AUC: 0.909
ğŸ” Computing optimal weights for ensemble...
Training base models:   0%|          | 0/4 [00:00<?, ?it/s]Training base models:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:02<00:07,  2.65s/it]Training base models:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:05,  2.68s/it]Training base models:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:24<00:10, 10.02s/it]Training base models: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:24<00:00,  6.13s/it]Training base models: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:24<00:00,  6.07s/it]
   lr: CV AUC = 0.755 (Â±0.021)
   rf: CV AUC = 0.845 (Â±0.019)
   svm: CV AUC = 0.948 (Â±0.009)
   nb: CV AUC = 0.820 (Â±0.019)

ğŸ“Š Optimal weights calculated:
   lr: 0.152
   rf: 0.239
   svm: 0.399
   nb: 0.210
ğŸ¯ Weighted Voting AUC: 0.935
ğŸ“ˆ Improvement: +2.6%

ğŸ—ï¸ STACKING ENSEMBLE
==============================
Training stacking models:   0%|          | 0/3 [00:00<?, ?it/s]Training stacking models:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:26<00:52, 26.40s/it]Training stacking models:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:47<00:23, 23.19s/it]Training stacking models: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [01:06<00:00, 21.27s/it]Training stacking models: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [01:06<00:00, 22.11s/it]
ğŸ¯ Stacking + LogisticRegression: AUC = 0.988
ğŸ¯ Stacking + RandomForest: AUC = 0.986
ğŸ¯ Stacking + SVM: AUC = 0.984

ğŸ† Best Stacking Model: LogisticRegression
ğŸ“Š Best Stacking AUC: 0.988

ğŸ“Š DETAILED CLASSIFICATION PERFORMANCE
   Baseline: AUC = 0.772
   Weighted_voting: AUC = 0.935
   Best_stacking: AUC = 0.988

ğŸ“‹ Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.95      0.95       355
           1       0.95      0.96      0.95       353

    accuracy                           0.95       708
   macro avg       0.95      0.95      0.95       708
weighted avg       0.95      0.95      0.95       708


ğŸ† ENSEMBLE RESULTS:
   Best method: best_stacking
   Best AUC: 0.988
   Improvement: +21.6%

âœ… Day 1 Results:
   Best method: best_stacking
   Best AUC: 0.988
   Improvement: +21.6%

==================================================
ğŸ¯ DAY 2: HYPERPARAMETER OPTIMIZATION
==================================================
ğŸš€ DAY 2: QUICK HYPERPARAMETER OPTIMIZATION
=======================================================
ğŸ“Š Baseline AUC: 0.760
ğŸ” OPTIMIZING LOGISTIC REGRESSION
   Best params: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}
   Best AUC: 0.763
ğŸŒ² OPTIMIZING RANDOM FOREST
   Best params: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}
   Best AUC: 0.927
âš¡ OPTIMIZING SVM
   Best params: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}
   Best AUC: 0.971
ğŸ‘¥ OPTIMIZING KNN
   Best params: {'n_neighbors': 10, 'weights': 'distance'}
   Best AUC: 0.917

ğŸ—ï¸ CREATING OPTIMIZED ENSEMBLE

ğŸ“Š EVALUATING OPTIMIZED ENSEMBLES
   Voting AUC: 0.944 (+18.4%)
   Stacking AUC: 0.983 (+22.3%)

ğŸ† BEST OPTIMIZED MODEL: Optimized Stacking
ğŸ“Š BEST AUC: 0.983
ğŸ“ˆ IMPROVEMENT: +22.3%

âœ… Day 2 Results:
   Best method: Optimized Stacking
   Best AUC: 0.983
   Improvement: +22.3%

==================================================
ğŸ“Š FINAL OPTIMIZATION SUMMARY
==================================================
ğŸ† BEST OVERALL RESULT:
   Method: Day 1: best_stacking
   Final AUC: 0.988
   Total Improvement: +23.4%
ğŸ‰ TARGET ACHIEVED! (0.820 ëª©í‘œ ë‹¬ì„±)

2ï¸âƒ£ Running validation analysis...
ğŸš€ COMPREHENSIVE VALIDATION ANALYSIS
=============================================
ğŸ“Š OVERFITTING ANALYSIS
==============================
Analyzing overfitting:   0%|          | 0/3 [00:00<?, ?it/s]Analyzing overfitting:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:00<00:00,  3.65it/s]Analyzing overfitting:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:55<00:32, 32.50s/it]Analyzing overfitting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [04:55<00:00, 127.23s/it]Analyzing overfitting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [04:55<00:00, 98.43s/it] 
Logistic Regression:
  Final Training AUC: 0.811
  Final Validation AUC: 0.760
  Overfitting Gap: 0.051 (Medium)
Random Forest:
  Final Training AUC: 1.000
  Final Validation AUC: 0.911
  Overfitting Gap: 0.089 (Medium)
Random Forest (Complex):
  Final Training AUC: 1.000
  Final Validation AUC: 0.937
  Overfitting Gap: 0.063 (Medium)

ğŸ”„ CROSS-VALIDATION ANALYSIS
===================================
Cross-validation analysis:   0%|          | 0/3 [00:00<?, ?it/s]
CV folds for Baseline (LR):   0%|          | 0/3 [00:00<?, ?it/s][A
CV folds for Baseline (LR): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 29.28it/s][A
                                                                         [ACross-validation analysis:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:00<00:00,  9.74it/s]Baseline (LR):
  3-fold CV: 0.760 (Â±0.015)
  5-fold CV: 0.760 (Â±0.023)
  10-fold CV: 0.766 (Â±0.030)

CV folds for Random Forest:   0%|          | 0/3 [00:00<?, ?it/s][A
CV folds for Random Forest:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:04<00:08,  4.49s/it][A
CV folds for Random Forest:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:13<00:07,  7.38s/it][A
CV folds for Random Forest: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:35<00:00, 13.69s/it][A
                                                                         [ACross-validation analysis:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:35<00:20, 20.69s/it]Random Forest:
  3-fold CV: 0.908 (Â±0.003)
  5-fold CV: 0.909 (Â±0.011)
  10-fold CV: 0.913 (Â±0.013)

CV folds for Optimized LR:   0%|          | 0/3 [00:00<?, ?it/s][A
CV folds for Optimized LR:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:00<00:00,  4.61it/s][A
CV folds for Optimized LR:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.51it/s][A
CV folds for Optimized LR: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.20it/s][A
                                                                        [ACross-validation analysis: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:37<00:00, 12.19s/it]Cross-validation analysis: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:37<00:00, 12.43s/it]
Optimized LR:
  3-fold CV: 0.766 (Â±0.012)
  5-fold CV: 0.765 (Â±0.020)
  10-fold CV: 0.770 (Â±0.028)

ğŸ“ˆ STATISTICAL SIGNIFICANCE TEST
========================================
Baseline AUC: 0.766 (Â±0.030)
Optimized AUC: 0.770 (Â±0.028)
Improvement: +0.4%
t-statistic: 3.612
p-value: 0.0056
Cohen's d: 0.122
Significance: ** (Significant)
Effect size: Small

ğŸ† BENCHMARK COMPARISON
============================
Literature Comparison (AUC):
--------------------------------------------------
Ranking benchmarks:   0%|          | 0/6 [00:00<?, ?it/s]                                                          1. ğŸ“Š Eye State Detection      : 0.950 (MBER + Feature Selection)
 2. ğŸ“Š Multi Attention (Opt)    : 0.941 (SVM + Optimized Features)
 3. ğŸ“Š Driver Fatigue (CNN)     : 0.837 (Deep Learning)
 4. ğŸ”¥ Our Method (Optimized)   : 0.827 (Ensemble + Optimization)
 5. ğŸ”¥ Our Method (Baseline)    : 0.760 (Logistic Regression + Band Power)
 6. ğŸ“Š Visual Attention (SVM)   : 0.744 (SVM + Band Power)

Our Performance Ranking:
  Baseline: 5/6 (83.3 percentile)
  Optimized: 4/6 (66.7 percentile)

ğŸ“‹ GENERATING VALIDATION REPORT
===================================
âœ… Validation report saved: /Users/hyeongsuk/Library/CloudStorage/OneDrive-ê°œì¸/HS_ë…¼ë¬¸ì‘ì„±/KOOS/results/paper_results/validation/validation_report.md

âœ… VALIDATION ANALYSIS COMPLETED!
ğŸ“ Results saved in: /Users/hyeongsuk/Library/CloudStorage/OneDrive-ê°œì¸/HS_ë…¼ë¬¸ì‘ì„±/KOOS/results/paper_results/validation

3ï¸âƒ£ Generating paper tables...
ğŸ“Š Generating Performance Comparison Table...
âœ… Table 1 saved: /Users/hyeongsuk/Library/CloudStorage/OneDrive-ê°œì¸/HS_ë…¼ë¬¸ì‘ì„±/KOOS/results/paper_results/table1_performance_comparison.tex
ğŸ“Š Generating Validation Summary Table...
âœ… Table 2 saved: table2_validation_summary.tex

4ï¸âƒ£ Generating paper figures...
ğŸ“Š Generating Benchmark Comparison Figure...
Highlighting our methods: 0it [00:00, ?it/s]                                            Adding AUC labels: 0it [00:00, ?it/s]                                     âœ… Figure 1 saved: figure1_benchmark_comparison.png
ğŸ“Š Generating Optimization Progress Figure...
Adding AUC progress labels: 0it [00:00, ?it/s]                                              Adding improvement labels: 0it [00:00, ?it/s]                                             2025-08-29 06:25:01,827 - ERROR - Error logged to: logs/errors/error_context_20250829_062501.json
2025-08-29 06:25:01,827 - ERROR - Real EEG optimization failed: Object of type VotingClassifier is not JSON serializable
âœ… Figure 2 saved: figure2_optimization_progress.png
âŒ Real EEG optimization failed: Object of type VotingClassifier is not JSON serializable

âŒ FAILED: Check error messages above.
